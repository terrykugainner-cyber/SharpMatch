# (1) æé«˜ç²¾åº¦çš„å»ºè­°èˆ‡æ–¹æ³•
_Exported on 11/11/2025 at 23:35:17 GMT+8 from Cursor (2.0.69)_

---

**User**

é‚„æœ‰æ²’æœ‰æé«˜ç²¾åº¦çš„å¯èƒ½æ€§. è«‹æä¾›å»ºè­°èˆ‡æ–¹æ³•

---

**Cursor**

æˆ‘ä¾†åˆ†æä¸€ä¸‹é€™å€‹ SharpMatch å°ˆæ¡ˆï¼Œäº†è§£ç•¶å‰çš„å¯¦ä½œä¸¦æä¾›æé«˜ç²¾åº¦çš„å»ºè­°ã€‚

è®“æˆ‘ç¹¼çºŒæŸ¥çœ‹ç›¸é—œæ¸¬è©¦æª”æ¡ˆå’Œç¯„ä¾‹ï¼Œä»¥æ›´å…¨é¢äº†è§£ç•¶å‰å¯¦ä½œçš„ç²¾åº¦æƒ…æ³ã€‚

è®“æˆ‘æŸ¥çœ‹æ›´å¤šç›¸é—œé…ç½®å’Œæ¸¬è©¦çµæœï¼š

ç¾åœ¨æˆ‘å·²ç¶“å…¨é¢äº†è§£äº† SharpMatch å°ˆæ¡ˆçš„å¯¦ä½œï¼Œè®“æˆ‘æä¾›æé«˜ç²¾åº¦çš„å»ºè­°å’Œæ–¹æ³•ï¼š

## SharpMatch æé«˜ç²¾åº¦çš„å»ºè­°èˆ‡æ–¹æ³•

æ ¹æ“šæˆ‘å°æ‚¨çš„å°ˆæ¡ˆåˆ†æï¼Œé€™æ˜¯ä¸€å€‹åŠŸèƒ½å®Œæ•´çš„æ¨¡æ¿åŒ¹é…ç³»çµ±ï¼ŒåŒ…å«äº† **ä»¿å°„åŒ¹é…ï¼ˆAffine Matchï¼‰**ã€**NCC åŒ¹é…**å’Œ **Chamfer è·é›¢åŒ¹é…**ã€‚ç›®å‰çš„è©•ä¼°çµæœé¡¯ç¤ºæº–ç¢ºç‡ä¸éŒ¯ï¼ˆ10å¼µåœ–ä¸­æœ‰8å¼µæ­£ç¢ºï¼‰ï¼Œä½†ä»æœ‰æå‡ç©ºé–“ã€‚ä»¥ä¸‹æ˜¯æé«˜ç²¾åº¦çš„å…·é«”å»ºè­°ï¼š

---

### **ğŸ¯ éšæ®µä¸€ï¼šç«‹å³å¯å¯¦æ–½çš„æ”¹é€²ï¼ˆé«˜å„ªå…ˆç´šï¼‰**

#### **1. å­åƒç´ ç²¾åº¦å„ªåŒ–**

**ç¾ç‹€**ï¼šæ‚¨å·²ç¶“å¯¦ä½œäº† `refine_peak_subpixel` å’Œéƒ¨åˆ†å„ªåŒ–åŠŸèƒ½

**æ”¹é€²å»ºè­°**ï¼š
```python
# åœ¨ sharp/ncc.py ä¸­å¢å¼· refine_match_iterative å‡½æ•¸
def refine_match_iterative_advanced(tpl, img, center_x, center_y, theta, scale,
                                     max_iters=10,  # å¢åŠ åˆ° 10 æ¬¡
                                     tol=1e-4,      # æ›´åš´æ ¼çš„æ”¶æ–‚æ¨™æº–
                                     mask=None,
                                     use_gradients=True):  # æ–°å¢ï¼šä½¿ç”¨æ¢¯åº¦å„ªåŒ–
    """
    æ”¹é€²ç‰ˆæœ¬ï¼šçµåˆæ•¸å€¼æ¢¯åº¦é€²è¡Œæ›´ç²¾ç¢ºçš„å„ªåŒ–
    """
    # åœ¨ç•¶å‰å¯¦ä½œåŸºç¤ä¸Šï¼Œæ·»åŠ æ¢¯åº¦ä¸‹é™æ­¥é©Ÿ
    # 1. ä½¿ç”¨æœ‰é™å·®åˆ†æ³•è¨ˆç®— NCC åˆ†æ•¸æ¢¯åº¦
    # 2. çµåˆ grid search å’Œ gradient descent
    # 3. ä½¿ç”¨ Levenberg-Marquardt ç®—æ³•ä»£æ›¿ç°¡å–® grid search
```

**é æœŸæ•ˆæœ**ï¼šä½ç½®ç²¾åº¦å¯æé«˜ 0.5-1 åƒç´ ï¼Œè§’åº¦ç²¾åº¦å¯æé«˜ 0.2-0.5 åº¦

---

#### **2. é›™éšæ®µç²¾ç´°åŒ–ç­–ç•¥**

**ç¾ç‹€**ï¼šæ‚¨å·²æœ‰ç²—åˆ°ç´°çš„é‡‘å­—å¡”æœç´¢

**æ”¹é€²å»ºè­°**ï¼š
```python
# åœ¨æ‰¾åˆ°åˆæ­¥åŒ¹é…å¾Œï¼Œå¢åŠ ç¬¬äºŒè¼ªç²¾ç´°åŒ–
def hybrid_refine_strategy(tpl, img, result, mask=None):
    """
    æ··åˆç²¾ç´°åŒ–ï¼šNCC + Chamfer è¯åˆå„ªåŒ–
    """
    # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ NCC ç²¾ç´°èª¿æ•´ä½ç½®å’Œè§’åº¦
    ncc_refined = refine_match_iterative(
        tpl, img, 
        result['x'], result['y'], 
        result['theta'], result['scale'],
        max_iters=10, 
        tol=1e-4,
        initial_ang_range=1.0,    # Â±1 åº¦
        initial_scale_range=0.01, # Â±0.01
        initial_pos_range=1.0,    # Â±1 åƒç´ 
        mask=mask
    )
    
    # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ Chamfer é©—è­‰ä¸¦å¾®èª¿ï¼ˆå°é‚Šç·£æ˜é¡¯çš„ç‰©é«”ç‰¹åˆ¥æœ‰æ•ˆï¼‰
    model = create(tpl, ...)
    chamfer_score = chamfer_score_rotated(
        model, img, 
        ncc_refined[1], ncc_refined[2],  # x, y
        ncc_refined[3], ncc_refined[4]   # theta, scale
    )
    
    # å¦‚æœ Chamfer åˆ†æ•¸é¡¯è‘—æé«˜ï¼Œä½¿ç”¨ Chamfer çµæœ
    # å¦å‰‡ä¿ç•™ NCC çµæœ
    return best_result
```

**é æœŸæ•ˆæœ**ï¼šçµåˆå…©ç¨®æ–¹æ³•çš„å„ªå‹¢ï¼Œå°ä¸åŒé¡å‹åœ–åƒï¼ˆç´‹ç†è±å¯Œ vs é‚Šç·£æ˜é¡¯ï¼‰éƒ½èƒ½ä¿æŒé«˜ç²¾åº¦

---

#### **3. å¤šå°ºåº¦ç‰¹å¾µé»å¢å¼·ï¼ˆé‡å° Affine Matchï¼‰**

**ç¾ç‹€**ï¼šä½¿ç”¨ SIFT/ORB/AKAZEï¼Œmax_keypoints=3000

**æ”¹é€²å»ºè­°**ï¼š

```python
# åœ¨ sharp/affine_match.py ä¸­æ”¹é€²ç‰¹å¾µæª¢æ¸¬
def detect_features_multiscale(img, detector_type='auto', max_keypoints=5000):
    """
    å¤šå°ºåº¦ç‰¹å¾µæª¢æ¸¬ï¼Œå¢åŠ ç‰¹å¾µé»æ•¸é‡å’Œè³ªé‡
    """
    if detector_type == 'auto' or detector_type == 'sift':
        # SIFT åƒæ•¸å„ªåŒ–
        detector = cv2.SIFT_create(
            nfeatures=max_keypoints,
            nOctaveLayers=4,        # å¢åŠ åˆ° 4 å±¤ï¼ˆé è¨­ 3ï¼‰
            contrastThreshold=0.03, # é™ä½é–¾å€¼ä»¥ç²å¾—æ›´å¤šç‰¹å¾µé»ï¼ˆé è¨­ 0.04ï¼‰
            edgeThreshold=8,        # é™ä½é‚Šç·£é–¾å€¼ï¼ˆé è¨­ 10ï¼‰
            sigma=1.4               # ç¨å¾®å¢åŠ é«˜æ–¯æ¨¡ç³Šï¼ˆé è¨­ 1.6ï¼‰
        )
```

**é¡å¤–å„ªåŒ–**ï¼šåœ¨ RANSAC éšæ®µä½¿ç”¨æ›´åš´æ ¼çš„åƒæ•¸
```python
def estimate_affine_partial_enhanced(kp1, kp2, matches, ...):
    # ä½¿ç”¨ MAGSAC++ ä»£æ›¿æ¨™æº– RANSACï¼ˆOpenCV 4.5.4+ï¼‰
    affine_matrix, inliers_mask = cv2.estimateAffinePartial2D(
        src_pts, dst_pts,
        method=cv2.USAC_MAGSAC,  # æ›´ç©©å¥çš„ä¼°è¨ˆå™¨
        ransacReprojThreshold=2.0,  # æ›´åš´æ ¼çš„é–¾å€¼ï¼ˆå¾ 3.0 é™ä½ï¼‰
        maxIters=5000,              # å¢åŠ è¿­ä»£æ¬¡æ•¸
        confidence=0.995,           # æé«˜ç½®ä¿¡åº¦
        refineIters=20              # å¢åŠ ç²¾ç´°åŒ–è¿­ä»£
    )
```

**é æœŸæ•ˆæœ**ï¼šå…§é»æ¯”ç‡å¯æé«˜ 5-10%ï¼Œè§’åº¦å’Œä½ç½®ç²¾åº¦æé«˜

---

### **ğŸš€ éšæ®µäºŒï¼šé€²éšå„ªåŒ–æ–¹æ³•ï¼ˆä¸­å„ªå…ˆç´šï¼‰**

#### **4. å…‰ç…§ä¸è®Šæ€§å¢å¼·**

**å•é¡Œ**ï¼šå…‰ç…§è®ŠåŒ–æœƒå½±éŸ¿ NCC å’Œç‰¹å¾µåŒ¹é…

**æ”¹é€²æ–¹æ¡ˆ**ï¼š
```python
def preprocess_lighting_invariant(img):
    """
    å…‰ç…§ä¸è®Šæ€§é è™•ç†
    """
    # æ–¹æ³• 1ï¼šCLAHEï¼ˆå°æ¯”åº¦å—é™è‡ªé©æ‡‰ç›´æ–¹åœ–å‡è¡¡ï¼‰
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    img_enhanced = clahe.apply(img)
    
    # æ–¹æ³• 2ï¼šRetinex æ¼”ç®—æ³•ï¼ˆæ›´å…ˆé€²ï¼‰
    # æˆ–ä½¿ç”¨ DoGï¼ˆDifference of Gaussiansï¼‰æ¿¾æ³¢
    
    return img_enhanced

# åœ¨åŒ¹é…å‰å°æ¨¡æ¿å’Œå ´æ™¯åœ–åƒéƒ½é€²è¡Œé è™•ç†
```

**é æœŸæ•ˆæœ**ï¼šåœ¨ä¸åŒå…‰ç…§æ¢ä»¶ä¸‹ï¼ŒåŒ¹é…æˆåŠŸç‡å¯æé«˜ 10-15%

---

#### **5. é‚Šç·£æ–¹å‘ä¸€è‡´æ€§æª¢é©—ï¼ˆé‡å° Chamferï¼‰**

**ç¾ç‹€**ï¼šæ‚¨çš„ Chamfer åƒ…ä½¿ç”¨è·é›¢ï¼Œæœªä½¿ç”¨æ–¹å‘ä¿¡æ¯

**æ”¹é€²å»ºè­°**ï¼š
```python
def create_with_orientation(img, roi, edge_threshold, sampling_step, use_polarity=True):
    """
    å¢å¼·ç‰ˆ shape_modelï¼ŒåŒ…å«é‚Šç·£æ–¹å‘ä¿¡æ¯
    """
    # è¨ˆç®—é‚Šç·£æ¢¯åº¦æ–¹å‘
    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)
    orientation = np.arctan2(sobely, sobelx)  # [-Ï€, Ï€]
    
    model['orientations'] = orientation[edge_points_y, edge_points_x]
    return model

def chamfer_score_rotated_with_orientation(model, image, ...):
    """
    ä½¿ç”¨æ–¹å‘ä¸€è‡´æ€§ä½œç‚ºé¡å¤–ç´„æŸ
    """
    # å°æ¯å€‹æ¨¡å‹é»ï¼Œä¸åƒ…æª¢æŸ¥è·é›¢ï¼Œé‚„æª¢æŸ¥æ–¹å‘å·®ç•°
    # orientation_diff = abs(model_orientation[i] - scene_orientation)
    # score = distance_score * orientation_score
```

**é æœŸæ•ˆæœ**ï¼šChamfer åŒ¹é…çš„è§’åº¦ç²¾åº¦å¯æé«˜ 2-5 åº¦ï¼Œæ¸›å°‘å°ç¨±ç‰©é«”çš„èª¤åŒ¹é…

---

#### **6. æ¨¡æ¿æ©ç¢¼ï¼ˆMaskï¼‰å„ªåŒ–**

**ç¾ç‹€**ï¼šæ‚¨å·²æ”¯æ´ maskï¼Œä½†å¯ä»¥æ›´æ™ºèƒ½åŒ–

**æ”¹é€²å»ºè­°**ï¼š
```python
def create_adaptive_mask(template):
    """
    è‡ªå‹•ç”Ÿæˆé«˜è³ªé‡ ROI mask
    """
    # æ–¹æ³• 1ï¼šä½¿ç”¨ GrabCut è‡ªå‹•åˆ†å‰²å‰æ™¯
    mask = np.zeros(template.shape[:2], np.uint8)
    bgd_model = np.zeros((1, 65), np.float64)
    fgd_model = np.zeros((1, 65), np.float64)
    
    rect = (10, 10, template.shape[1]-20, template.shape[0]-20)
    cv2.grabCut(template, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)
    
    # æ–¹æ³• 2ï¼šåŸºæ–¼é¡¯è‘—æ€§æª¢æ¸¬
    # ä½¿ç”¨ cv2.saliency æ¨¡çµ„
    
    # æ–¹æ³• 3ï¼šé‚Šç·£å¯†åº¦åˆ†æ
    # ä¿ç•™é‚Šç·£å¯†åº¦é«˜çš„å€åŸŸï¼Œå¿½ç•¥èƒŒæ™¯
    
    return mask

# åœ¨ NCC å’Œ Chamfer ä¸­éƒ½ä½¿ç”¨é€™å€‹ mask
```

**é æœŸæ•ˆæœ**ï¼šå°æœ‰è¤‡é›œèƒŒæ™¯çš„æ¨¡æ¿ï¼ŒåŒ¹é…æº–ç¢ºç‡å¯æé«˜ 15-20%

---

### **ğŸ”¬ éšæ®µä¸‰ï¼šæ·±åº¦å­¸ç¿’å¢å¼·ï¼ˆé•·æœŸè¦åŠƒï¼‰**

#### **7. æ·±åº¦ç‰¹å¾µæè¿°å­**

**æ–¹æ¡ˆ**ï¼šçµåˆå‚³çµ±æ–¹æ³•èˆ‡æ·±åº¦å­¸ç¿’
```python
# ä½¿ç”¨é è¨“ç·´çš„ç‰¹å¾µæå–ç¶²è·¯ï¼ˆå¦‚ SuperPoint, D2-Netï¼‰
# æ›¿ä»£æˆ–è¼”åŠ© SIFT ç‰¹å¾µ
import torch
from models.superpoint import SuperPoint

def detect_deep_features(img):
    model = SuperPoint(weights='superpoint_v1')
    keypoints, descriptors, scores = model(img)
    return keypoints, descriptors
```

**é æœŸæ•ˆæœ**ï¼šå°å…‰ç…§ã€è¦–è§’è®ŠåŒ–æ›´é­¯æ£’ï¼ŒåŒ¹é…æˆåŠŸç‡å¯æé«˜ 20-30%

---

#### **8. å­¸ç¿’å‹ç²¾ç´°åŒ–ç¶²çµ¡**

**æ–¹æ¡ˆ**ï¼šè¨“ç·´ä¸€å€‹å°å‹ CNN ä¾†é æ¸¬ç²¾ç´°åç§»
```python
# åœ¨ç²—åŒ¹é…å¾Œï¼Œä½¿ç”¨ç¥ç¶“ç¶²çµ¡é æ¸¬ç²¾ç¢ºä½ç½®
class RefineNet(nn.Module):
    def __init__(self):
        # è¼¸å…¥ï¼štemplate patch + scene patch (aligned by coarse match)
        # è¼¸å‡ºï¼š(Î”x, Î”y, Î”Î¸, Î”s) ç²¾ç´°èª¿æ•´é‡
        ...

# è¨“ç·´æ•¸æ“šï¼šåˆæˆå¤§é‡å·²çŸ¥è®Šæ›çš„æ¨£æœ¬
```

**é æœŸæ•ˆæœ**ï¼šå¯å°‡ç²¾åº¦æé«˜åˆ°äºåƒç´ ç´šåˆ¥ï¼ˆ0.1-0.2 åƒç´ ï¼‰

---

### **ğŸ“Š éšæ®µå››ï¼šç³»çµ±å„ªåŒ–èˆ‡è©•ä¼°**

#### **9. å¤šå€™é¸æŠ•ç¥¨æ©Ÿåˆ¶**

**ç¾ç‹€**ï¼šå–å–®ä¸€æœ€ä½³åŒ¹é…

**æ”¹é€²**ï¼š
```python
def ensemble_matching(template, scene):
    """
    é›†æˆå¤šç¨®æ–¹æ³•çš„çµæœ
    """
    # æ–¹æ³• 1ï¼šAffine Match
    result_affine = affine_match(...)
    
    # æ–¹æ³• 2ï¼šNCC + Rotation
    result_ncc = multi_match_ncc_rotated(...)
    
    # æ–¹æ³• 3ï¼šChamfer + Rotation
    result_chamfer = grid_search_theta_scale_chamfer(...)
    
    # æŠ•ç¥¨æˆ–åŠ æ¬Šèåˆ
    final_result = weighted_fusion([
        (result_affine, weight=0.4),
        (result_ncc, weight=0.4),
        (result_chamfer, weight=0.2)
    ])
    
    return final_result
```

**é æœŸæ•ˆæœ**ï¼šæº–ç¢ºç‡å¯æé«˜ 10-15%ï¼Œå°ä¸åŒå ´æ™¯æ›´ç©©å¥

---

#### **10. è‡ªé©æ‡‰åƒæ•¸èª¿æ•´**

**æ–¹æ¡ˆ**ï¼šæ ¹æ“šåœ–åƒç‰¹æ€§è‡ªå‹•èª¿æ•´åƒæ•¸
```python
def auto_tune_parameters(template, scene):
    """
    è‡ªå‹•åˆ†æåœ–åƒç‰¹æ€§ï¼Œé¸æ“‡æœ€ä½³åƒæ•¸
    """
    # åˆ†æç´‹ç†è±å¯Œåº¦
    texture_score = cv2.Laplacian(template, cv2.CV_64F).var()
    
    # åˆ†æé‚Šç·£å¼·åº¦
    edges = cv2.Canny(template, 50, 150)
    edge_ratio = np.sum(edges > 0) / edges.size
    
    if texture_score > 500:
        # ç´‹ç†è±å¯Œï¼šå„ªå…ˆ SIFT + NCC
        return {'method': 'ncc', 'detector': 'sift', ...}
    elif edge_ratio > 0.1:
        # é‚Šç·£æ˜é¡¯ï¼šå„ªå…ˆ Chamfer
        return {'method': 'chamfer', ...}
    else:
        # æ··åˆæ–¹æ³•
        return {'method': 'hybrid', ...}
```

---

### **ğŸ“ˆ æ•ˆæœé ä¼°ç¸½çµ**

| æ”¹é€²æ–¹æ³• | å¯¦æ–½é›£åº¦ | é æœŸç²¾åº¦æå‡ | å‚™è¨» |
|---------|---------|------------|------|
| å­åƒç´ ç²¾åº¦å„ªåŒ– | ä½ | +0.5-1 åƒç´  | ç«‹å³å¯¦æ–½ |
| é›™éšæ®µç²¾ç´°åŒ– | ä½ | +5-10% | ç«‹å³å¯¦æ–½ |
| å¤šå°ºåº¦ç‰¹å¾µå¢å¼· | ä¸­ | +5-10% | ä¸€é€±å…§ |
| å…‰ç…§ä¸è®Šæ€§ | ä¸­ | +10-15% | ä¸€é€±å…§ |
| é‚Šç·£æ–¹å‘æª¢é©— | ä¸­ | +2-5Â° è§’åº¦ç²¾åº¦ | å…©é€±å…§ |
| Mask å„ªåŒ– | ä½ | +15-20%ï¼ˆç‰¹å®šå ´æ™¯ï¼‰| ç«‹å³å¯¦æ–½ |
| æ·±åº¦å­¸ç¿’ç‰¹å¾µ | é«˜ | +20-30% | é•·æœŸè¦åŠƒ |
| é›†æˆæŠ•ç¥¨ | ä¸­ | +10-15% | å…©é€±å…§ |

---

### **ğŸ¯ å…·é«”å¯¦æ–½å»ºè­°ï¼ˆæœ¬é€±å¯åšï¼‰**

1. **å„ªå…ˆå¯¦æ–½**ï¼š
   - å­åƒç´ ç²¾åº¦å„ªåŒ–ï¼ˆä¿®æ”¹ `refine_match_iterative`ï¼‰
   - æ”¹é€² RANSAC åƒæ•¸ï¼ˆé™ä½é–¾å€¼åˆ° 2.0ï¼‰
   - å¢åŠ  SIFT contrastThresholdï¼ˆç²å¾—æ›´å¤šç‰¹å¾µé»ï¼‰

2. **æ¸¬è©¦é©—è­‰**ï¼š
   - åœ¨æ‚¨çš„ 10 å¼µæ¸¬è©¦åœ–ä¸Šè©•ä¼°æ”¹é€²æ•ˆæœ
   - ç‰¹åˆ¥é—œæ³¨ç›®å‰å¤±æ•—çš„å…©å¼µåœ–ï¼ˆ0004, 0007ï¼‰

3. **ä»£ç¢¼ç¤ºä¾‹**ï¼šæˆ‘å¯ä»¥æä¾›å…·é«”çš„ä»£ç¢¼å¯¦ä½œï¼Œä½†å› ç‚ºæ‚¨ç›®å‰åœ¨ ask æ¨¡å¼ï¼Œæˆ‘ç„¡æ³•ç›´æ¥ä¿®æ”¹æª”æ¡ˆã€‚å¦‚æœéœ€è¦ï¼Œå¯ä»¥åˆ‡æ›åˆ° agent æ¨¡å¼è®“æˆ‘å¹«æ‚¨å¯¦ä½œé€™äº›æ”¹é€²ã€‚

---

æ‚¨æƒ³è¦æˆ‘é‡å°å“ªå€‹æ–¹æ³•æä¾›æ›´è©³ç´°çš„å¯¦ä½œä»£ç¢¼ï¼Ÿæˆ–è€…æ‚¨æƒ³å…ˆå¾å“ªå€‹å„ªåŒ–é–‹å§‹ï¼Ÿ

```python
# åœ¨ sharp/ncc.py ä¸­å¢å¼· refine_match_iterative å‡½æ•¸
def refine_match_iterative_advanced(tpl, img, center_x, center_y, theta, scale,
                                     max_iters=10,  # å¢åŠ åˆ° 10 æ¬¡
                                     tol=1e-4,      # æ›´åš´æ ¼çš„æ”¶æ–‚æ¨™æº–
                                     mask=None,
                                     use_gradients=True):  # æ–°å¢ï¼šä½¿ç”¨æ¢¯åº¦å„ªåŒ–
    """
    æ”¹é€²ç‰ˆæœ¬ï¼šçµåˆæ•¸å€¼æ¢¯åº¦é€²è¡Œæ›´ç²¾ç¢ºçš„å„ªåŒ–
    """
    # åœ¨ç•¶å‰å¯¦ä½œåŸºç¤ä¸Šï¼Œæ·»åŠ æ¢¯åº¦ä¸‹é™æ­¥é©Ÿ
    # 1. ä½¿ç”¨æœ‰é™å·®åˆ†æ³•è¨ˆç®— NCC åˆ†æ•¸æ¢¯åº¦
    # 2. çµåˆ grid search å’Œ gradient descent
    # 3. ä½¿ç”¨ Levenberg-Marquardt ç®—æ³•ä»£æ›¿ç°¡å–® grid search
```

```python
# åœ¨æ‰¾åˆ°åˆæ­¥åŒ¹é…å¾Œï¼Œå¢åŠ ç¬¬äºŒè¼ªç²¾ç´°åŒ–
def hybrid_refine_strategy(tpl, img, result, mask=None):
    """
    æ··åˆç²¾ç´°åŒ–ï¼šNCC + Chamfer è¯åˆå„ªåŒ–
    """
    # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ NCC ç²¾ç´°èª¿æ•´ä½ç½®å’Œè§’åº¦
    ncc_refined = refine_match_iterative(
        tpl, img, 
        result['x'], result['y'], 
        result['theta'], result['scale'],
        max_iters=10, 
        tol=1e-4,
        initial_ang_range=1.0,    # Â±1 åº¦
        initial_scale_range=0.01, # Â±0.01
        initial_pos_range=1.0,    # Â±1 åƒç´ 
        mask=mask
    )
    
    # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ Chamfer é©—è­‰ä¸¦å¾®èª¿ï¼ˆå°é‚Šç·£æ˜é¡¯çš„ç‰©é«”ç‰¹åˆ¥æœ‰æ•ˆï¼‰
    model = create(tpl, ...)
    chamfer_score = chamfer_score_rotated(
        model, img, 
        ncc_refined[1], ncc_refined[2],  # x, y
        ncc_refined[3], ncc_refined[4]   # theta, scale
    )
    
    # å¦‚æœ Chamfer åˆ†æ•¸é¡¯è‘—æé«˜ï¼Œä½¿ç”¨ Chamfer çµæœ
    # å¦å‰‡ä¿ç•™ NCC çµæœ
    return best_result
```

```python
# åœ¨ sharp/affine_match.py ä¸­æ”¹é€²ç‰¹å¾µæª¢æ¸¬
def detect_features_multiscale(img, detector_type='auto', max_keypoints=5000):
    """
    å¤šå°ºåº¦ç‰¹å¾µæª¢æ¸¬ï¼Œå¢åŠ ç‰¹å¾µé»æ•¸é‡å’Œè³ªé‡
    """
    if detector_type == 'auto' or detector_type == 'sift':
        # SIFT åƒæ•¸å„ªåŒ–
        detector = cv2.SIFT_create(
            nfeatures=max_keypoints,
            nOctaveLayers=4,        # å¢åŠ åˆ° 4 å±¤ï¼ˆé è¨­ 3ï¼‰
            contrastThreshold=0.03, # é™ä½é–¾å€¼ä»¥ç²å¾—æ›´å¤šç‰¹å¾µé»ï¼ˆé è¨­ 0.04ï¼‰
            edgeThreshold=8,        # é™ä½é‚Šç·£é–¾å€¼ï¼ˆé è¨­ 10ï¼‰
            sigma=1.4               # ç¨å¾®å¢åŠ é«˜æ–¯æ¨¡ç³Šï¼ˆé è¨­ 1.6ï¼‰
        )
```

```python
def estimate_affine_partial_enhanced(kp1, kp2, matches, ...):
    # ä½¿ç”¨ MAGSAC++ ä»£æ›¿æ¨™æº– RANSACï¼ˆOpenCV 4.5.4+ï¼‰
    affine_matrix, inliers_mask = cv2.estimateAffinePartial2D(
        src_pts, dst_pts,
        method=cv2.USAC_MAGSAC,  # æ›´ç©©å¥çš„ä¼°è¨ˆå™¨
        ransacReprojThreshold=2.0,  # æ›´åš´æ ¼çš„é–¾å€¼ï¼ˆå¾ 3.0 é™ä½ï¼‰
        maxIters=5000,              # å¢åŠ è¿­ä»£æ¬¡æ•¸
        confidence=0.995,           # æé«˜ç½®ä¿¡åº¦
        refineIters=20              # å¢åŠ ç²¾ç´°åŒ–è¿­ä»£
    )
```

```python
def preprocess_lighting_invariant(img):
    """
    å…‰ç…§ä¸è®Šæ€§é è™•ç†
    """
    # æ–¹æ³• 1ï¼šCLAHEï¼ˆå°æ¯”åº¦å—é™è‡ªé©æ‡‰ç›´æ–¹åœ–å‡è¡¡ï¼‰
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    img_enhanced = clahe.apply(img)
    
    # æ–¹æ³• 2ï¼šRetinex æ¼”ç®—æ³•ï¼ˆæ›´å…ˆé€²ï¼‰
    # æˆ–ä½¿ç”¨ DoGï¼ˆDifference of Gaussiansï¼‰æ¿¾æ³¢
    
    return img_enhanced

# åœ¨åŒ¹é…å‰å°æ¨¡æ¿å’Œå ´æ™¯åœ–åƒéƒ½é€²è¡Œé è™•ç†
```

```python
def create_with_orientation(img, roi, edge_threshold, sampling_step, use_polarity=True):
    """
    å¢å¼·ç‰ˆ shape_modelï¼ŒåŒ…å«é‚Šç·£æ–¹å‘ä¿¡æ¯
    """
    # è¨ˆç®—é‚Šç·£æ¢¯åº¦æ–¹å‘
    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)
    orientation = np.arctan2(sobely, sobelx)  # [-Ï€, Ï€]
    
    model['orientations'] = orientation[edge_points_y, edge_points_x]
    return model

def chamfer_score_rotated_with_orientation(model, image, ...):
    """
    ä½¿ç”¨æ–¹å‘ä¸€è‡´æ€§ä½œç‚ºé¡å¤–ç´„æŸ
    """
    # å°æ¯å€‹æ¨¡å‹é»ï¼Œä¸åƒ…æª¢æŸ¥è·é›¢ï¼Œé‚„æª¢æŸ¥æ–¹å‘å·®ç•°
    # orientation_diff = abs(model_orientation[i] - scene_orientation)
    # score = distance_score * orientation_score
```

```python
def create_adaptive_mask(template):
    """
    è‡ªå‹•ç”Ÿæˆé«˜è³ªé‡ ROI mask
    """
    # æ–¹æ³• 1ï¼šä½¿ç”¨ GrabCut è‡ªå‹•åˆ†å‰²å‰æ™¯
    mask = np.zeros(template.shape[:2], np.uint8)
    bgd_model = np.zeros((1, 65), np.float64)
    fgd_model = np.zeros((1, 65), np.float64)
    
    rect = (10, 10, template.shape[1]-20, template.shape[0]-20)
    cv2.grabCut(template, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)
    
    # æ–¹æ³• 2ï¼šåŸºæ–¼é¡¯è‘—æ€§æª¢æ¸¬
    # ä½¿ç”¨ cv2.saliency æ¨¡çµ„
    
    # æ–¹æ³• 3ï¼šé‚Šç·£å¯†åº¦åˆ†æ
    # ä¿ç•™é‚Šç·£å¯†åº¦é«˜çš„å€åŸŸï¼Œå¿½ç•¥èƒŒæ™¯
    
    return mask

# åœ¨ NCC å’Œ Chamfer ä¸­éƒ½ä½¿ç”¨é€™å€‹ mask
```

```python
# ä½¿ç”¨é è¨“ç·´çš„ç‰¹å¾µæå–ç¶²è·¯ï¼ˆå¦‚ SuperPoint, D2-Netï¼‰
# æ›¿ä»£æˆ–è¼”åŠ© SIFT ç‰¹å¾µ
import torch
from models.superpoint import SuperPoint

def detect_deep_features(img):
    model = SuperPoint(weights='superpoint_v1')
    keypoints, descriptors, scores = model(img)
    return keypoints, descriptors
```

```python
# åœ¨ç²—åŒ¹é…å¾Œï¼Œä½¿ç”¨ç¥ç¶“ç¶²çµ¡é æ¸¬ç²¾ç¢ºä½ç½®
class RefineNet(nn.Module):
    def __init__(self):
        # è¼¸å…¥ï¼štemplate patch + scene patch (aligned by coarse match)
        # è¼¸å‡ºï¼š(Î”x, Î”y, Î”Î¸, Î”s) ç²¾ç´°èª¿æ•´é‡
        ...

# è¨“ç·´æ•¸æ“šï¼šåˆæˆå¤§é‡å·²çŸ¥è®Šæ›çš„æ¨£æœ¬
```

```python
def ensemble_matching(template, scene):
    """
    é›†æˆå¤šç¨®æ–¹æ³•çš„çµæœ
    """
    # æ–¹æ³• 1ï¼šAffine Match
    result_affine = affine_match(...)
    
    # æ–¹æ³• 2ï¼šNCC + Rotation
    result_ncc = multi_match_ncc_rotated(...)
    
    # æ–¹æ³• 3ï¼šChamfer + Rotation
    result_chamfer = grid_search_theta_scale_chamfer(...)
    
    # æŠ•ç¥¨æˆ–åŠ æ¬Šèåˆ
    final_result = weighted_fusion([
        (result_affine, weight=0.4),
        (result_ncc, weight=0.4),
        (result_chamfer, weight=0.2)
    ])
    
    return final_result
```

```python
def auto_tune_parameters(template, scene):
    """
    è‡ªå‹•åˆ†æåœ–åƒç‰¹æ€§ï¼Œé¸æ“‡æœ€ä½³åƒæ•¸
    """
    # åˆ†æç´‹ç†è±å¯Œåº¦
    texture_score = cv2.Laplacian(template, cv2.CV_64F).var()
    
    # åˆ†æé‚Šç·£å¼·åº¦
    edges = cv2.Canny(template, 50, 150)
    edge_ratio = np.sum(edges > 0) / edges.size
    
    if texture_score > 500:
        # ç´‹ç†è±å¯Œï¼šå„ªå…ˆ SIFT + NCC
        return {'method': 'ncc', 'detector': 'sift', ...}
    elif edge_ratio > 0.1:
        # é‚Šç·£æ˜é¡¯ï¼šå„ªå…ˆ Chamfer
        return {'method': 'chamfer', ...}
    else:
        # æ··åˆæ–¹æ³•
        return {'method': 'hybrid', ...}
```

---

**User**

å°‡ä½ çš„ "ç²¾åº¦æå‡å»ºè­°" è¼¸å‡ºæˆmdèªªæ˜æª” 

---

**Cursor**

æˆ‘ä¾†ç‚ºæ‚¨å‰µå»ºä¸€å€‹å®Œæ•´çš„ç²¾åº¦æå‡å»ºè­°æ–‡æª”ã€‚

```markdown
# SharpMatch ç²¾åº¦æå‡æŒ‡å—

## ğŸ“‹ ç›®éŒ„

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç•¶å‰ç‹€æ…‹åˆ†æ](#ç•¶å‰ç‹€æ…‹åˆ†æ)
- [éšæ®µä¸€ï¼šç«‹å³å¯å¯¦æ–½çš„æ”¹é€²ï¼ˆé«˜å„ªå…ˆç´šï¼‰](#éšæ®µä¸€ç«‹å³å¯å¯¦æ–½çš„æ”¹é€²é«˜å„ªå…ˆç´š)
- [éšæ®µäºŒï¼šé€²éšå„ªåŒ–æ–¹æ³•ï¼ˆä¸­å„ªå…ˆç´šï¼‰](#éšæ®µäºŒé€²éšå„ªåŒ–æ–¹æ³•ä¸­å„ªå…ˆç´š)
- [éšæ®µä¸‰ï¼šæ·±åº¦å­¸ç¿’å¢å¼·ï¼ˆé•·æœŸè¦åŠƒï¼‰](#éšæ®µä¸‰æ·±åº¦å­¸ç¿’å¢å¼·é•·æœŸè¦åŠƒ)
- [éšæ®µå››ï¼šç³»çµ±å„ªåŒ–èˆ‡è©•ä¼°](#éšæ®µå››ç³»çµ±å„ªåŒ–èˆ‡è©•ä¼°)
- [å¯¦æ–½è·¯ç·šåœ–](#å¯¦æ–½è·¯ç·šåœ–)
- [æ•ˆæœé ä¼°ç¸½çµ](#æ•ˆæœé ä¼°ç¸½çµ)

---

## æ¦‚è¿°

æœ¬æ–‡æª”æä¾› SharpMatch æ¨¡æ¿åŒ¹é…ç³»çµ±çš„ç²¾åº¦æå‡æ–¹æ¡ˆï¼Œæ¶µè“‹å¾å¿«é€Ÿæ”¹é€²åˆ°é•·æœŸè¦åŠƒçš„å®Œæ•´ç­–ç•¥ã€‚SharpMatch æ•´åˆäº†ä¸‰ç¨®æ ¸å¿ƒåŒ¹é…æŠ€è¡“ï¼š

1. **ä»¿å°„åŒ¹é…ï¼ˆAffine Matchï¼‰** - åŸºæ–¼ç‰¹å¾µé»ï¼ˆSIFT/ORB/AKAZEï¼‰
2. **NCC åŒ¹é…** - æ­¸ä¸€åŒ–äº’ç›¸é—œ
3. **Chamfer è·é›¢åŒ¹é…** - åŸºæ–¼é‚Šç·£è¼ªå»“

ç•¶å‰è©•ä¼°çµæœï¼š**10 å¼µæ¸¬è©¦åœ–åƒä¸­ 8 å¼µæˆåŠŸ**ï¼ˆTP=8, FN=2ï¼‰ï¼Œå…·æœ‰è‰¯å¥½çš„åŸºç¤ä½†ä»æœ‰æå‡ç©ºé–“ã€‚

---

## ç•¶å‰ç‹€æ…‹åˆ†æ

### ğŸ¯ ç¾æœ‰å„ªå‹¢

- âœ… å®Œæ•´çš„ä¸‰ç¨®åŒ¹é…æ–¹æ³•å¯¦ç¾
- âœ… é‡‘å­—å¡”å¤šå°ºåº¦æœç´¢
- âœ… å­åƒç´ ç²¾åº¦å„ªåŒ–åŠŸèƒ½
- âœ… è¿­ä»£ç²¾ç´°åŒ–æ”¯æŒ
- âœ… ä¸¦è¡ŒåŒ–è¨ˆç®—æ”¯æŒ
- âœ… NMSï¼ˆéæ¥µå¤§å€¼æŠ‘åˆ¶ï¼‰å»é‡

### âš ï¸ å¾…æ”¹é€²é ˜åŸŸ

- ğŸ”¸ å­åƒç´ ç²¾åº¦å„ªåŒ–ç®—æ³•å¯ä»¥æ›´å…ˆé€²
- ğŸ”¸ RANSAC åƒæ•¸å¯ä»¥æ›´åš´æ ¼
- ğŸ”¸ ç‰¹å¾µé»æ•¸é‡å’Œè³ªé‡å¯ä»¥æå‡
- ğŸ”¸ å…‰ç…§è®ŠåŒ–é©æ‡‰æ€§
- ğŸ”¸ é‚Šç·£æ–¹å‘ä¿¡æ¯æœªå……åˆ†åˆ©ç”¨
- ğŸ”¸ å¤šæ–¹æ³•èåˆæ©Ÿåˆ¶

### ğŸ“Š å¤±æ•—æ¡ˆä¾‹åˆ†æ

æ ¹æ“š `verify_data/eval_result_per_image.csv`ï¼š
- **0004.png** - å¤±æ•—ï¼ˆFN=1ï¼‰
- **0007.png** - å¤±æ•—ï¼ˆFN=1ï¼‰

å¯èƒ½åŸå› ï¼š
- å…‰ç…§è®ŠåŒ–éå¤§
- ç‰¹å¾µé»ä¸è¶³
- é®æ“‹æˆ–éƒ¨åˆ†å¯è¦‹
- è§’åº¦æˆ–ç¸®æ”¾è¶…å‡ºæœç´¢ç¯„åœ

---

## éšæ®µä¸€ï¼šç«‹å³å¯å¯¦æ–½çš„æ”¹é€²ï¼ˆé«˜å„ªå…ˆç´šï¼‰

### 1. å­åƒç´ ç²¾åº¦å„ªåŒ– â­â­â­

#### å•é¡Œæè¿°
ç•¶å‰çš„ `refine_match_iterative` ä½¿ç”¨ç°¡å–®çš„ grid searchï¼Œç²¾åº¦å—é™æ–¼æœç´¢æ­¥é•·ã€‚

#### æ”¹é€²æ–¹æ¡ˆ

**æ–¹æ³• Aï¼šæ¢¯åº¦è¼”åŠ©å„ªåŒ–**

```python
# åœ¨ sharp/ncc.py ä¸­æ·»åŠ 
def refine_match_gradient_descent(tpl, img, center_x, center_y, theta, scale,
                                   max_iters=20, learning_rate=0.5, tol=1e-4, mask=None):
    """
    ä½¿ç”¨æœ‰é™å·®åˆ†æ¢¯åº¦ä¸‹é™é€²è¡Œç²¾ç´°åŒ–
    
    Args:
        tpl: æ¨¡æ¿åœ–åƒ
        img: å ´æ™¯åœ–åƒ
        center_x, center_y: åˆå§‹ä½ç½®
        theta: åˆå§‹è§’åº¦ï¼ˆå¼§åº¦ï¼‰
        scale: åˆå§‹ç¸®æ”¾
        max_iters: æœ€å¤§è¿­ä»£æ¬¡æ•¸
        learning_rate: å­¸ç¿’ç‡
        tol: æ”¶æ–‚å®¹å·®
        mask: å¯é¸çš„æ¨¡æ¿ mask
    
    Returns:
        (best_score, best_x, best_y, best_theta, best_scale)
    """
    tpl = _to_gray(tpl)
    img = _to_gray(img)
    
    # åˆå§‹åŒ–åƒæ•¸
    params = np.array([center_x, center_y, theta, scale], dtype=np.float64)
    
    # æ­¥é•·ç”¨æ–¼æ•¸å€¼æ¢¯åº¦è¨ˆç®—
    epsilon = np.array([0.5, 0.5, np.deg2rad(0.2), 0.005])
    
    best_score = ncc_score_rotated(tpl, img, params[0], params[1], params[2], params[3], mask)
    prev_score = best_score
    
    for iteration in range(max_iters):
        # è¨ˆç®—æ•¸å€¼æ¢¯åº¦ï¼ˆæœ‰é™å·®åˆ†æ³•ï¼‰
        gradient = np.zeros(4, dtype=np.float64)
        
        for i in range(4):
            # å‰å‘å·®åˆ†
            params_plus = params.copy()
            params_plus[i] += epsilon[i]
            score_plus = ncc_score_rotated(tpl, img, 
                                           params_plus[0], params_plus[1], 
                                           params_plus[2], params_plus[3], mask)
            
            # å¾Œå‘å·®åˆ†
            params_minus = params.copy()
            params_minus[i] -= epsilon[i]
            score_minus = ncc_score_rotated(tpl, img,
                                            params_minus[0], params_minus[1],
                                            params_minus[2], params_minus[3], mask)
            
            # ä¸­å¿ƒå·®åˆ†
            gradient[i] = (score_plus - score_minus) / (2.0 * epsilon[i])
        
        # æ¢¯åº¦ä¸Šå‡ï¼ˆå› ç‚ºæˆ‘å€‘è¦æœ€å¤§åŒ–åˆ†æ•¸ï¼‰
        # ä½¿ç”¨è‡ªé©æ‡‰å­¸ç¿’ç‡
        adaptive_lr = learning_rate / (1.0 + iteration * 0.1)
        params += adaptive_lr * gradient
        
        # è¨ˆç®—æ–°åˆ†æ•¸
        new_score = ncc_score_rotated(tpl, img, params[0], params[1], params[2], params[3], mask)
        
        # å¦‚æœåˆ†æ•¸æé«˜ï¼Œæ›´æ–°æœ€ä½³åƒæ•¸
        if new_score > best_score:
            best_score = new_score
        
        # æª¢æŸ¥æ”¶æ–‚
        if abs(new_score - prev_score) < tol:
            break
        
        prev_score = new_score
    
    return (best_score, params[0], params[1], params[2], params[3])
```

**æ–¹æ³• Bï¼šæ‹‹ç‰©ç·šæ’å€¼**

```python
def refine_peak_parabolic(scoremap, px, py):
    """
    ä½¿ç”¨æ‹‹ç‰©ç·šæ’å€¼é€²è¡Œå­åƒç´ ç²¾åº¦å„ªåŒ–
    
    Args:
        scoremap: 2D åˆ†æ•¸åœ–
        px, py: æ•´æ•¸å³°å€¼ä½ç½®
    
    Returns:
        (subpx_x, subpx_y): å­åƒç´ å³°å€¼ä½ç½®
    """
    h, w = scoremap.shape
    
    # ç¢ºä¿ä¸åœ¨é‚Šç•Œä¸Š
    if px <= 0 or px >= w - 1 or py <= 0 or py >= h - 1:
        return float(px), float(py)
    
    # æå– 3x3 é„°åŸŸ
    v00 = float(scoremap[py-1, px-1])
    v01 = float(scoremap[py-1, px])
    v02 = float(scoremap[py-1, px+1])
    v10 = float(scoremap[py, px-1])
    v11 = float(scoremap[py, px])
    v12 = float(scoremap[py, px+1])
    v20 = float(scoremap[py+1, px-1])
    v21 = float(scoremap[py+1, px])
    v22 = float(scoremap[py+1, px+1])
    
    # X æ–¹å‘çš„æ‹‹ç‰©ç·šæ“¬åˆ
    # f(x) = a*x^2 + b*x + c
    # ä½¿ç”¨ä¸‰é»ï¼š(-1, v10), (0, v11), (1, v12)
    # é ‚é»ï¼šx_peak = -b / (2*a)
    denom_x = 2.0 * (v10 + v12 - 2.0 * v11)
    if abs(denom_x) > 1e-8:
        dx = (v10 - v12) / denom_x
    else:
        dx = 0.0
    
    # Y æ–¹å‘çš„æ‹‹ç‰©ç·šæ“¬åˆ
    denom_y = 2.0 * (v01 + v21 - 2.0 * v11)
    if abs(denom_y) > 1e-8:
        dy = (v01 - v21) / denom_y
    else:
        dy = 0.0
    
    # é™åˆ¶åç§»ç¯„åœï¼ˆé˜²æ­¢ç•°å¸¸å€¼ï¼‰
    dx = np.clip(dx, -0.5, 0.5)
    dy = np.clip(dy, -0.5, 0.5)
    
    subpx_x = float(px) + dx
    subpx_y = float(py) + dy
    
    return subpx_x, subpx_y
```

**å¯¦æ–½æ­¥é©Ÿï¼š**
1. åœ¨ `sharp/ncc.py` ä¸­æ·»åŠ ä¸Šè¿°å…©å€‹å‡½æ•¸
2. åœ¨ `multi_match_ncc_rotated` ä¸­ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›¿ä»£æˆ–è¼”åŠ©è¿­ä»£å„ªåŒ–
3. åœ¨ `topk_peaks` ä¸­ä½¿ç”¨æ‹‹ç‰©ç·šæ’å€¼æ›¿ä»£åŠ æ¬Šè³ªå¿ƒæ³•

**é æœŸæ•ˆæœï¼š**
- ä½ç½®ç²¾åº¦ï¼šÂ±0.3 åƒç´ ï¼ˆç•¶å‰ç´„ Â±1 åƒç´ ï¼‰
- è§’åº¦ç²¾åº¦ï¼šÂ±0.2 åº¦ï¼ˆç•¶å‰ç´„ Â±0.5 åº¦ï¼‰
- æˆåŠŸç‡æå‡ï¼š5-10%

---

### 2. é›™éšæ®µç²¾ç´°åŒ–ç­–ç•¥ â­â­â­

#### å•é¡Œæè¿°
ç•¶å‰æ¯ç¨®æ–¹æ³•ç¨ç«‹é‹è¡Œï¼Œæœªå……åˆ†åˆ©ç”¨å¤šæ–¹æ³•äº’è£œå„ªå‹¢ã€‚

#### æ”¹é€²æ–¹æ¡ˆ

```python
# åœ¨ sharp/affine_match.py ä¸­æ·»åŠ 
def hybrid_refine_match(template, scene, coarse_result, 
                        use_ncc=True, use_chamfer=True, mask=None):
    """
    æ··åˆç²¾ç´°åŒ–ï¼šçµåˆ NCC å’Œ Chamfer çš„å„ªå‹¢
    
    æµç¨‹ï¼š
    1. ä½¿ç”¨ç²—åŒ¹é…çµæœä½œç‚ºåˆå§‹å€¼
    2. NCC ç²¾ç´°èª¿æ•´ä½ç½®å’Œè§’åº¦ï¼ˆå°ç´‹ç†æ•æ„Ÿï¼‰
    3. Chamfer é©—è­‰ä¸¦å¾®èª¿ï¼ˆå°é‚Šç·£æ•æ„Ÿï¼‰
    4. é¸æ“‡æœ€ä½³çµæœ
    
    Args:
        template: æ¨¡æ¿åœ–åƒ
        scene: å ´æ™¯åœ–åƒ
        coarse_result: ç²—åŒ¹é…çµæœ dictï¼ŒåŒ…å« 'affine_matrix', 'params' ç­‰
        use_ncc: æ˜¯å¦ä½¿ç”¨ NCC ç²¾ç´°åŒ–
        use_chamfer: æ˜¯å¦ä½¿ç”¨ Chamfer ç²¾ç´°åŒ–
        mask: å¯é¸çš„æ¨¡æ¿ mask
    
    Returns:
        dict: ç²¾ç´°åŒ–å¾Œçš„çµæœï¼ŒåŒ…å«æœ€ä½³åŒ¹é…åƒæ•¸å’Œåˆ†æ•¸
    """
    from .ncc import refine_match_iterative
    from .shape_model import create
    from .shape_match import chamfer_score_rotated
    
    results = []
    
    # å¾ç²—åŒ¹é…æå–åƒæ•¸
    params = coarse_result['params']
    init_x = params['tx']
    init_y = params['ty']
    init_theta = params['theta_rad']
    init_scale = params['scale']
    
    # éšæ®µ 1ï¼šNCC ç²¾ç´°åŒ–
    if use_ncc:
        ncc_refined = refine_match_iterative(
            template, scene,
            init_x, init_y, init_theta, init_scale,
            max_iters=15,
            tol=1e-4,
            mask=mask,
            initial_ang_range=2.0,    # Â±2 åº¦
            initial_scale_range=0.02, # Â±0.02
            initial_pos_range=3.0     # Â±3 åƒç´ 
        )
        
        results.append({
            'method': 'ncc',
            'score': ncc_refined[0],
            'x': ncc_refined[1],
            'y': ncc_refined[2],
            'theta': ncc_refined[3],
            'scale': ncc_refined[4]
        })
    
    # éšæ®µ 2ï¼šChamfer ç²¾ç´°åŒ–
    if use_chamfer:
        # å‰µå»ºå½¢ç‹€æ¨¡å‹
        tpl_h, tpl_w = template.shape[:2]
        model = create(template, (0, 0, tpl_w, tpl_h),
                      edge_threshold=(60, 140),
                      sampling_step=2,
                      use_polarity=False)
        
        # åœ¨ NCC çµæœé™„è¿‘æœç´¢ï¼ˆå¦‚æœæœ‰ NCC çµæœï¼‰
        if results:
            search_x = results[0]['x']
            search_y = results[0]['y']
            search_theta = results[0]['theta']
            search_scale = results[0]['scale']
        else:
            search_x = init_x
            search_y = init_y
            search_theta = init_theta
            search_scale = init_scale
        
        # Chamfer ç¶²æ ¼æœç´¢
        from .shape_match import grid_search_theta_scale_chamfer
        
        ang_grid = np.linspace(search_theta - np.deg2rad(3), 
                              search_theta + np.deg2rad(3), 13)
        scale_grid = np.linspace(search_scale - 0.03, 
                                search_scale + 0.03, 7)
        
        chamfer_candidates = grid_search_theta_scale_chamfer(
            model, scene, search_x, search_y,
            ang_grid, scale_grid, topk=1
        )
        
        if chamfer_candidates:
            results.append({
                'method': 'chamfer',
                'score': chamfer_candidates[0][0],
                'x': chamfer_candidates[0][1],
                'y': chamfer_candidates[0][2],
                'theta': chamfer_candidates[0][3],
                'scale': chamfer_candidates[0][4]
            })
    
    # é¸æ“‡æœ€ä½³çµæœï¼ˆå¯ä»¥ä½¿ç”¨åŠ æ¬Šèåˆæˆ–ç°¡å–®é¸æœ€é«˜åˆ†ï¼‰
    if not results:
        return coarse_result
    
    # ç°¡å–®ç­–ç•¥ï¼šé¸æ“‡åˆ†æ•¸æœ€é«˜çš„
    best_result = max(results, key=lambda r: r['score'])
    
    # æ§‹å»ºè¿”å›çµæœï¼ˆèˆ‡ affine_match æ ¼å¼å…¼å®¹ï¼‰
    refined_matrix = np.array([
        [best_result['scale'] * np.cos(best_result['theta']),
         -best_result['scale'] * np.sin(best_result['theta']),
         best_result['x']],
        [best_result['scale'] * np.sin(best_result['theta']),
         best_result['scale'] * np.cos(best_result['theta']),
         best_result['y']]
    ], dtype=np.float32)
    
    refined_params = decompose_affine_matrix(refined_matrix)
    
    return {
        'affine_matrix': refined_matrix,
        'params': refined_params,
        'refine_method': best_result['method'],
        'refine_score': best_result['score'],
        'all_candidates': results,
        **coarse_result  # ä¿ç•™åŸå§‹çµæœ
    }
```

**ä½¿ç”¨æ–¹å¼ï¼š**

```python
# åœ¨ run_verify_match.py æˆ–å…¶ä»–åŒ¹é…è…³æœ¬ä¸­
result = affine_match(template, scene, ...)

# ç²¾ç´°åŒ–
refined_result = hybrid_refine_match(template, scene, result, 
                                     use_ncc=True, use_chamfer=True)
```

**é æœŸæ•ˆæœï¼š**
- å°ä¸åŒé¡å‹åœ–åƒï¼ˆç´‹ç†è±å¯Œ vs é‚Šç·£æ˜é¡¯ï¼‰éƒ½èƒ½ä¿æŒé«˜ç²¾åº¦
- æˆåŠŸç‡æå‡ï¼š5-10%
- å°å…‰ç…§è®ŠåŒ–æ›´ç©©å¥

---

### 3. å¤šå°ºåº¦ç‰¹å¾µé»å¢å¼· â­â­

#### å•é¡Œæè¿°
ç•¶å‰ç‰¹å¾µæª¢æ¸¬å™¨ä½¿ç”¨é»˜èªåƒæ•¸ï¼Œåœ¨æŸäº›å ´æ™¯ä¸‹ç‰¹å¾µé»æ•¸é‡å’Œè³ªé‡ä¸è¶³ã€‚

#### æ”¹é€²æ–¹æ¡ˆ

**A. å„ªåŒ– SIFT åƒæ•¸**

```python
# åœ¨ sharp/affine_match.py ä¸­ä¿®æ”¹ detect_features å‡½æ•¸
def detect_features(img, detector_type='auto', max_keypoints=3000):
    """æª¢æ¸¬åœ–åƒç‰¹å¾µé»å’Œæè¿°å­ï¼ˆå¢å¼·ç‰ˆï¼‰ã€‚
    
    Args:
        img: è¼¸å…¥åœ–åƒï¼ˆç°åº¦æˆ– BGRï¼‰
        detector_type: æª¢æ¸¬å™¨é¡å‹ ('auto', 'sift', 'orb', 'akaze')
        max_keypoints: æœ€å¤šç‰¹å¾µé»æ•¸é‡
    
    Returns:
        (actual_detector_type, key
```

```markdown
# SharpMatch ç²¾åº¦æå‡å®Œæ•´æŒ‡å—

> ç‰ˆæœ¬ï¼šv1.0  
> æ—¥æœŸï¼š2025-11-11  
> ä½œè€…ï¼šSharpMatch é–‹ç™¼åœ˜éšŠ

## ğŸ“‹ ç›®éŒ„

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç•¶å‰ç‹€æ…‹åˆ†æ](#ç•¶å‰ç‹€æ…‹åˆ†æ)
- [éšæ®µä¸€ï¼šç«‹å³å¯å¯¦æ–½çš„æ”¹é€²ï¼ˆé«˜å„ªå…ˆç´šï¼‰](#éšæ®µä¸€ç«‹å³å¯å¯¦æ–½çš„æ”¹é€²é«˜å„ªå…ˆç´š)
- [éšæ®µäºŒï¼šé€²éšå„ªåŒ–æ–¹æ³•ï¼ˆä¸­å„ªå…ˆç´šï¼‰](#éšæ®µäºŒé€²éšå„ªåŒ–æ–¹æ³•ä¸­å„ªå…ˆç´š)
- [éšæ®µä¸‰ï¼šæ·±åº¦å­¸ç¿’å¢å¼·ï¼ˆé•·æœŸè¦åŠƒï¼‰](#éšæ®µä¸‰æ·±åº¦å­¸ç¿’å¢å¼·é•·æœŸè¦åŠƒ)
- [éšæ®µå››ï¼šç³»çµ±å„ªåŒ–èˆ‡è©•ä¼°](#éšæ®µå››ç³»çµ±å„ªåŒ–èˆ‡è©•ä¼°)
- [æ•ˆæœé ä¼°ç¸½çµ](#æ•ˆæœé ä¼°ç¸½çµ)
- [å¯¦æ–½è·¯ç·šåœ–](#å¯¦æ–½è·¯ç·šåœ–)

---

## æ¦‚è¿°

æœ¬æŒ‡å—é‡å° SharpMatch è¦–è¦ºåŒ¹é…ç³»çµ±æä¾›ç³»çµ±æ€§çš„ç²¾åº¦æå‡æ–¹æ¡ˆã€‚SharpMatch æ•´åˆäº†ä¸‰ç¨®ä¸»è¦åŒ¹é…æŠ€è¡“ï¼š

1. **ä»¿å°„åŒ¹é…ï¼ˆAffine Matchï¼‰** - åŸºæ–¼ç‰¹å¾µé»ï¼ˆSIFT/ORB/AKAZEï¼‰+ RANSAC
2. **NCC åŒ¹é…** - æ­¸ä¸€åŒ–äº’ç›¸é—œï¼ˆæ”¯æŒæ—‹è½‰å’Œç¸®æ”¾ï¼‰
3. **Chamfer åŒ¹é…** - åŸºæ–¼è·é›¢è®Šæ›çš„å½¢ç‹€åŒ¹é…

ç•¶å‰ç³»çµ±åœ¨ 10 å¼µæ¸¬è©¦åœ–åƒä¸Šé”åˆ° **80% æº–ç¢ºç‡**ï¼ˆ8/10ï¼‰ï¼Œæœ¬æŒ‡å—å°‡å¹«åŠ©æ‚¨é€²ä¸€æ­¥æå‡åˆ° **95%+** çš„æº–ç¢ºç‡ã€‚

---

## ç•¶å‰ç‹€æ…‹åˆ†æ

### ç¾æœ‰å„ªå‹¢

âœ… **å¤šå°ºåº¦é‡‘å­—å¡”æœç´¢** - ç²—åˆ°ç´°çš„é«˜æ•ˆæœç´¢ç­–ç•¥  
âœ… **å­åƒç´ ç²¾åº¦å„ªåŒ–** - å·²å¯¦ç¾åŸºç¤çš„å­åƒç´ å®šä½  
âœ… **æ··åˆåŒ¹é…ç­–ç•¥** - Chamfer ç²—å®šä½ + Affine ç´°å®šä½  
âœ… **NMS å»é‡æ©Ÿåˆ¶** - æœ‰æ•ˆè™•ç†å¤šç‰©ä»¶æª¢æ¸¬  
âœ… **Mask æ”¯æ´** - å¯é™åˆ¶åŒ¹é…å€åŸŸ  

### æ”¹é€²ç©ºé–“

âš ï¸ **å­åƒç´ ç²¾åº¦** - å¯é€²ä¸€æ­¥å„ªåŒ–åˆ° 0.1-0.2 åƒç´ ç´šåˆ¥  
âš ï¸ **å…‰ç…§é­¯æ£’æ€§** - å°å…‰ç…§è®ŠåŒ–çš„é©æ‡‰æ€§å¯å¢å¼·  
âš ï¸ **è§’åº¦ç²¾åº¦** - ç‰¹åˆ¥æ˜¯åœ¨å¤§è§’åº¦æ—‹è½‰æ™‚ï¼ˆ>45Â°ï¼‰  
âš ï¸ **ç‰¹å¾µé»è³ªé‡** - å¯æå–æ›´å¤šé«˜è³ªé‡ç‰¹å¾µé»  
âš ï¸ **é‚Šç·£æ–¹å‘åˆ©ç”¨** - Chamfer æœªå……åˆ†åˆ©ç”¨æ–¹å‘ä¿¡æ¯  

---

## éšæ®µä¸€ï¼šç«‹å³å¯å¯¦æ–½çš„æ”¹é€²ï¼ˆé«˜å„ªå…ˆç´šï¼‰

### 1. å­åƒç´ ç²¾åº¦å„ªåŒ– â­â­â­

**å¯¦æ–½é›£åº¦**ï¼šâ­ ä½  
**é æœŸæ•ˆæœ**ï¼šä½ç½®ç²¾åº¦ +0.5-1 åƒç´ ï¼Œè§’åº¦ç²¾åº¦ +0.2-0.5Â°

#### èƒŒæ™¯

ç•¶å‰çš„ `refine_match_iterative` ä½¿ç”¨ç¶²æ ¼æœç´¢ï¼Œé›–ç„¶å·²ç¶“å¾ˆå¥½ï¼Œä½†å¯ä»¥çµåˆæ¢¯åº¦ä¿¡æ¯é€²ä¸€æ­¥æå‡ã€‚

#### æ”¹é€²æ–¹æ¡ˆ

åœ¨ `sharp/ncc.py` ä¸­å¢å¼·ç¾æœ‰å‡½æ•¸ï¼š

```python
def refine_match_gradient_descent(tpl, img, center_x, center_y, theta, scale,
                                   max_iters=15, 
                                   learning_rate=0.5,
                                   tol=1e-4,
                                   mask=None):
    """
    ä½¿ç”¨æ¢¯åº¦ä¸‹é™é€²è¡Œç²¾ç´°å„ªåŒ–
    
    ç›¸æ¯”ç´”ç¶²æ ¼æœç´¢ï¼Œæ¢¯åº¦ä¸‹é™å¯ä»¥æ›´å¿«é€Ÿåœ°æ”¶æ–‚åˆ°æœ€å„ªè§£ã€‚
    çµåˆæ•¸å€¼æ¢¯åº¦å’Œè‡ªé©æ‡‰å­¸ç¿’ç‡ï¼Œæä¾›æ›´ç²¾ç¢ºçš„å®šä½ã€‚
    
    Args:
        tpl: æ¨¡æ¿åœ–åƒ
        img: å ´æ™¯åœ–åƒ
        center_x, center_y: åˆå§‹ä½ç½®
        theta: åˆå§‹è§’åº¦ï¼ˆå¼§åº¦ï¼‰
        scale: åˆå§‹ç¸®æ”¾
        max_iters: æœ€å¤§è¿­ä»£æ¬¡æ•¸
        learning_rate: åˆå§‹å­¸ç¿’ç‡
        tol: æ”¶æ–‚å®¹å·®
        mask: å¯é¸çš„æ¨¡æ¿ mask
    
    Returns:
        (best_score, best_x, best_y, best_theta, best_scale)
    """
    tpl = _to_gray(tpl)
    img = _to_gray(img)
    
    # åƒæ•¸å‘é‡: [x, y, theta, scale]
    params = np.array([center_x, center_y, theta, scale], dtype=np.float64)
    
    # æ­¥é•·ï¼ˆç”¨æ–¼æ•¸å€¼æ¢¯åº¦è¨ˆç®—ï¼‰
    delta_x = 0.5      # åƒç´ 
    delta_y = 0.5      # åƒç´ 
    delta_theta = 0.005  # ç´„ 0.29 åº¦
    delta_scale = 0.005
    
    deltas = np.array([delta_x, delta_y, delta_theta, delta_scale])
    
    # è¨ˆç®—åˆå§‹åˆ†æ•¸
    current_score = ncc_score_rotated(tpl, img, params[0], params[1], 
                                      params[2], params[3], mask)
    
    lr = learning_rate  # è‡ªé©æ‡‰å­¸ç¿’ç‡
    
    for iteration in range(max_iters):
        # è¨ˆç®—æ•¸å€¼æ¢¯åº¦ï¼ˆå››ç¶­ï¼‰
        gradient = np.zeros(4, dtype=np.float64)
        
        for i in range(4):
            params_plus = params.copy()
            params_plus[i] += deltas[i]
            score_plus = ncc_score_rotated(tpl, img, params_plus[0], params_plus[1],
                                          params_plus[2], params_plus[3], mask)
            
            params_minus = params.copy()
            params_minus[i] -= deltas[i]
            score_minus = ncc_score_rotated(tpl, img, params_minus[0], params_minus[1],
                                           params_minus[2], params_minus[3], mask)
            
            # ä¸­å¿ƒå·®åˆ†
            gradient[i] = (score_plus - score_minus) / (2 * deltas[i])
        
        # æ¢¯åº¦ä¸Šå‡ï¼ˆå› ç‚ºæˆ‘å€‘è¦æœ€å¤§åŒ–åˆ†æ•¸ï¼‰
        params_new = params + lr * gradient
        
        # ç´„æŸåƒæ•¸ç¯„åœ
        # è§’åº¦ç¯„åœ [-Ï€, Ï€]
        params_new[2] = np.arctan2(np.sin(params_new[2]), np.cos(params_new[2]))
        # ç¸®æ”¾ç¯„åœ [0.5, 2.0]
        params_new[3] = np.clip(params_new[3], 0.5, 2.0)
        
        # è¨ˆç®—æ–°åˆ†æ•¸
        new_score = ncc_score_rotated(tpl, img, params_new[0], params_new[1],
                                      params_new[2], params_new[3], mask)
        
        # è‡ªé©æ‡‰å­¸ç¿’ç‡
        if new_score > current_score:
            # æ¥å—æ–°åƒæ•¸
            score_improvement = new_score - current_score
            params = params_new
            current_score = new_score
            
            # å¦‚æœæ”¹é€²å¾ˆå¥½ï¼Œç¨å¾®å¢åŠ å­¸ç¿’ç‡
            if score_improvement > tol * 10:
                lr = min(lr * 1.1, learning_rate * 2)
        else:
            # æ‹’çµ•æ–°åƒæ•¸ï¼Œé™ä½å­¸ç¿’ç‡
            lr *= 0.5
        
        # æª¢æŸ¥æ”¶æ–‚
        gradient_norm = np.linalg.norm(gradient)
        if gradient_norm < tol or lr < 1e-6:
            break
    
    return (current_score, params[0], params[1], params[2], params[3])
```

#### ä½¿ç”¨æ–¹å¼

```python
# åœ¨æ‰¾åˆ°åˆæ­¥åŒ¹é…å¾Œ
result = affine_match(template, scene)

# ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç²¾ç´°åŒ–
from sharp.ncc import refine_match_gradient_descent

refined_score, x, y, theta, scale = refine_match_gradient_descent(
    template, scene,
    result['params']['tx'],
    result['params']['ty'],
    result['params']['theta_rad'],
    result['params']['scale'],
    max_iters=15,
    learning_rate=0.5
)

print(f"ç²¾ç´°åŒ–å¾Œä½ç½®: ({x:.2f}, {y:.2f}), è§’åº¦: {np.rad2deg(theta):.2f}Â°, ç¸®æ”¾: {scale:.3f}")
```

---

### 2. é›™éšæ®µç²¾ç´°åŒ–ç­–ç•¥ â­â­â­

**å¯¦æ–½é›£åº¦**ï¼šâ­ ä½  
**é æœŸæ•ˆæœ**ï¼šæ•´é«”æº–ç¢ºç‡ +5-10%

#### ç†å¿µ

çµåˆ NCC å’Œ Chamfer çš„å„ªå‹¢ï¼š
- **NCC**ï¼šå°ç´‹ç†è±å¯Œçš„å€åŸŸæ•æ„Ÿï¼Œç²¾åº¦é«˜
- **Chamfer**ï¼šå°é‚Šç·£æ˜é¡¯çš„ç‰©é«”é­¯æ£’ï¼ŒæŠ—å™ªæ€§å¼·

#### å¯¦ä½œ

åœ¨ `sharp/affine_match.py` ä¸­æ·»åŠ æ–°å‡½æ•¸ï¼š

```python
def hybrid_refine_strategy(template, scene, initial_result, mask=None, verbose=False):
    """
    æ··åˆç²¾ç´°åŒ–ç­–ç•¥ï¼šNCC + Chamfer è¯åˆå„ªåŒ–
    
    å·¥ä½œæµç¨‹ï¼š
    1. ä½¿ç”¨ NCC é€²è¡Œç²¾ç´°ä½ç½®å’Œè§’åº¦èª¿æ•´
    2. ä½¿ç”¨ Chamfer é©—è­‰ä¸¦å¾®èª¿ï¼ˆç‰¹åˆ¥å°é‚Šç·£æ˜é¡¯çš„ç‰©é«”ï¼‰
    3. æ¯”è¼ƒå…©ç¨®æ–¹æ³•çš„ä¿¡å¿ƒåˆ†æ•¸ï¼Œé¸æ“‡æœ€ä½³çµæœ
    
    Args:
        template: æ¨¡æ¿åœ–åƒ
        scene: å ´æ™¯åœ–åƒ
        initial_result: åˆæ­¥åŒ¹é…çµæœï¼ˆä¾†è‡ª affine_match æˆ–å…¶ä»–æ–¹æ³•ï¼‰
        mask: å¯é¸çš„æ¨¡æ¿ mask
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
    
    Returns:
        refined_result: ç²¾ç´°åŒ–å¾Œçš„çµæœå­—å…¸
    """
    from .ncc import refine_match_iterative
    from .shape_model import create
    from .shape_match import chamfer_score_rotated
    
    # æå–åˆå§‹åƒæ•¸
    tx = initial_result['params']['tx']
    ty = initial_result['params']['ty']
    theta = initial_result['params']['theta_rad']
    scale = initial_result['params']['scale']
    
    if verbose:
        print(f"[æ··åˆç²¾ç´°åŒ–] åˆå§‹åƒæ•¸: ä½ç½®=({tx:.1f}, {ty:.1f}), è§’åº¦={np.rad2deg(theta):.2f}Â°, ç¸®æ”¾={scale:.3f}")
    
    # ========== ç¬¬ä¸€æ­¥ï¼šNCC ç²¾ç´°åŒ– ==========
    ncc_score, ncc_x, ncc_y, ncc_theta, ncc_scale = refine_match_iterative(
        template, scene,
        center_x=tx,
        center_y=ty,
        theta=theta,
        scale=scale,
        max_iters=10,
        tol=1e-4,
        mask=mask,
        initial_ang_range=1.0,      # Â±1 åº¦
        initial_scale_range=0.01,   # Â±0.01
        initial_pos_range=1.0       # Â±1 åƒç´ 
    )
    
    if verbose:
        print(f"[NCC ç²¾ç´°åŒ–] åˆ†æ•¸={ncc_score:.4f}, ä½ç½®=({ncc_x:.2f}, {ncc_y:.2f}), "
              f"è§’åº¦={np.rad2deg(ncc_theta):.2f}Â°, ç¸®æ”¾={ncc_scale:.3f}")
    
    # ========== ç¬¬äºŒæ­¥ï¼šChamfer é©—è­‰ ==========
    # å‰µå»ºå½¢ç‹€æ¨¡å‹
    tpl_h, tpl_w = template.shape[:2]
    model = create(template, (0, 0, tpl_w, tpl_h),
                   edge_threshold=(60, 140),
                   sampling_step=2,
                   use_polarity=False)
    
    # è¨ˆç®— Chamfer åˆ†æ•¸
    chamfer_score = chamfer_score_rotated(
        model, scene,
        center_x=ncc_x,
        center_y=ncc_y,
        theta=ncc_theta,
        scale=ncc_scale,
        use_weights=True
    )
    
    if verbose:
        print(f"[Chamfer é©—è­‰] åˆ†æ•¸={chamfer_score:.4f}")
    
    # ========== ç¬¬ä¸‰æ­¥ï¼šå¯é¸çš„ Chamfer å¾®èª¿ ==========
    # å¦‚æœ Chamfer åˆ†æ•¸ä¸å¤ å¥½ï¼Œå˜—è©¦åœ¨ NCC çµæœé™„è¿‘æœç´¢
    if chamfer_score < 0.7:  # é–¾å€¼å¯èª¿æ•´
        if verbose:
            print(f"[Chamfer å¾®èª¿] Chamfer åˆ†æ•¸è¼ƒä½ï¼Œé€²è¡Œå±€éƒ¨æœç´¢...")
        
        from .shape_match import grid_search_theta_scale_chamfer
        
        # åœ¨ NCC çµæœé™„è¿‘é€²è¡Œå°ç¯„åœ Chamfer æœç´¢
        ang_grid = np.linspace(ncc_theta - np.deg2rad(2), 
                               ncc_theta + np.deg2rad(2), 9)
        scales = np.linspace(ncc_scale - 0.02, ncc_scale + 0.02, 5)
        
        chamfer_results = grid_search_theta_scale_chamfer(
            model, scene,
            center_x=ncc_x,
            center_y=ncc_y,
            ang_grid=ang_grid,
            scales=scales,
            topk=1,
            use_weights=True
        )
        
        if chamfer_results:
            chamfer_score_new, cx, cy, theta_new, scale_new = chamfer_results[0]
            
            if chamfer_score_new > chamfer_score * 1.1:  # æ”¹é€²è¶…é 10%
                if verbose:
                    print(f"[Chamfer å¾®èª¿] æ‰¾åˆ°æ›´å¥½çš„çµæœ: åˆ†æ•¸={chamfer_score_new:.4f}")
                ncc_x, ncc_y = cx, cy
                ncc_theta, ncc_scale = theta_new, scale_new
                chamfer_score = chamfer_score_new
    
    # ========== ç¬¬å››æ­¥ï¼šç¶œåˆè©•åˆ† ==========
    # ç¶œåˆ NCC å’Œ Chamfer åˆ†æ•¸
    # æ¬Šé‡å¯æ ¹æ“šå¯¦éš›å ´æ™¯èª¿æ•´
    combined_score = 0.6 * ncc_score + 0.4 * chamfer_score
    
    if verbose:
        print(f"[æœ€çµ‚çµæœ] ç¶œåˆåˆ†æ•¸={combined_score:.4f}, "
              f"ä½ç½®=({ncc_x:.2f}, {ncc_y:.2f}), "
              f"è§’åº¦={np.rad2deg(ncc_theta):.2f}Â°, "
              f"ç¸®æ”¾={ncc_scale:.3f}")
    
    # æ§‹å»ºç²¾ç´°åŒ–çµæœ
    refined_result = initial_result.copy()
    refined_result['params']['tx'] = ncc_x
    refined_result['params']['ty'] = ncc_y
    refined_result['params']['theta_rad'] = ncc_theta
    refined_result['params']['theta_deg'] = np.rad2deg(ncc_theta)
    refined_result['params']['scale'] = ncc_scale
    refined_result['ncc_score'] = ncc_score
    refined_result['chamfer_score'] = chamfer_score
    refined_result['combined_score'] = combined_score
    refined_result['refined'] = True
    
    return refined_result
```

#### ä½¿ç”¨ç¯„ä¾‹

```python
# æ¨™æº–åŒ¹é…æµç¨‹
result = affine_match(template, scene)

# æ‡‰ç”¨æ··åˆç²¾ç´°åŒ–
refined_result = hybrid_refine_strategy(
    template, scene, result,
    mask=None,
    verbose=True
)

print(f"ç²¾ç´°åŒ–æå‡: {refined_result['combined_score'] - result['inlier_ratio']:.2%}")
```

---

### 3. å¤šå°ºåº¦ç‰¹å¾µé»å¢å¼· â­â­

**å¯¦æ–½é›£åº¦**ï¼šâ­â­ ä¸­  
**é æœŸæ•ˆæœ**ï¼šç‰¹å¾µé»æ•¸é‡ +30-50%ï¼Œå…§é»æ¯”ç‡ +5-10%

#### å•é¡Œåˆ†æ

ç•¶å‰ `detect_features` å‡½æ•¸ä½¿ç”¨é»˜èªåƒæ•¸ï¼Œåœ¨æŸäº›æƒ…æ³ä¸‹ç‰¹å¾µé»æ•¸é‡ä¸è¶³ï¼š

```python
# ç•¶å‰å¯¦ä½œï¼ˆç°¡åŒ–ï¼‰
detector = cv2.SIFT_create(nfeatures=max_keypoints)
```

#### å„ªåŒ–æ–¹æ¡ˆ

åœ¨ `sharp/affine_match.py` ä¸­æ”¹é€² `detect_features` å‡½æ•¸ï¼š

```python
def detect_features_enhanced(img, detector_type='auto', max_keypoints=5000,
                             enhance_contrast=True, verbose=False):
    """
    å¢å¼·ç‰ˆç‰¹å¾µæª¢æ¸¬ï¼šå„ªåŒ–åƒæ•¸ï¼Œæå–æ›´å¤šé«˜è³ªé‡ç‰¹å¾µé»
    
    æ”¹é€²é»ï¼š
    1. SIFT åƒæ•¸å„ªåŒ–ï¼šæ›´å¤šå°ºåº¦å±¤ï¼Œæ›´ä½å°æ¯”åº¦é–¾å€¼
    2. å¯é¸çš„å°æ¯”åº¦å¢å¼·é è™•ç†
    3. å¤šå°ºåº¦æª¢æ¸¬ç­–ç•¥
    
    Args:
        img: è¼¸å…¥åœ–åƒï¼ˆç°åº¦æˆ– BGRï¼‰
        detector_type: æª¢æ¸¬å™¨é¡å‹ ('auto', 'sift', 'orb', 'akaze')
        max_keypoints: æœ€å¤šç‰¹å¾µé»æ•¸é‡ï¼ˆå¢åŠ åˆ° 5000ï¼‰
        enhance_contrast: æ˜¯å¦é€²è¡Œå°æ¯”åº¦å¢å¼·ï¼ˆå»ºè­° Trueï¼‰
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
    
    Returns:
        (actual_detector_type, keypoints, descriptors)
    """
    if img.ndim == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()
    
    # å¯é¸ï¼šå°æ¯”åº¦å¢å¼·
    if enhance_contrast:
        # CLAHEï¼ˆå°æ¯”åº¦å—é™è‡ªé©æ‡‰ç›´æ–¹åœ–å‡è¡¡ï¼‰
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)
        if verbose:
            print("[ç‰¹å¾µæª¢æ¸¬] å·²æ‡‰ç”¨ CLAHE å°æ¯”åº¦å¢å¼·")
    
    # è‡ªå‹•é¸æ“‡æª¢æ¸¬å™¨
    actual_detector_type = detector_type
    if detector_type == 'auto':
        try:
            # å„ªå…ˆä½¿ç”¨ SIFT
            detector = cv2.SIFT_create(
                nfeatures=max_keypoints,
                nOctaveLayers=4,           # å¢åŠ åˆ° 4 å±¤ï¼ˆé»˜èª 3ï¼‰
                contrastThreshold=0.03,    # é™ä½é–¾å€¼ï¼ˆé»˜èª 0.04ï¼‰
                edgeThreshold=8,           # é™ä½é‚Šç·£é–¾å€¼ï¼ˆé»˜èª 10ï¼‰
                sigma=1.4                  # åˆå§‹é«˜æ–¯æ¨¡ç³Š sigmaï¼ˆé»˜èª 1.6ï¼‰
            )
            actual_detector_type = 'sift'
            if verbose:
                print(f"[ç‰¹å¾µæª¢æ¸¬] ä½¿ç”¨å„ªåŒ–çš„ SIFT æª¢æ¸¬å™¨")
        except:
            # SIFT ä¸å¯ç”¨ï¼Œå›é€€åˆ° ORB
            detector = cv2.ORB_create(
                nfeatures=max_keypoints,
                scaleFactor=1.2,           # é‡‘å­—å¡”ç¸®æ”¾å› å­
                nlevels=8,                 # é‡‘å­—å¡”å±¤æ•¸
                edgeThreshold=15,          # é‚Šç·£é–¾å€¼
                firstLevel=0,
                WTA_K=2,
                scoreType=cv2.ORB_HARRIS_SCORE,
                patchSize=31,
                fastThreshold=20
            )
            actual_detector_type = 'orb'
            if verbose:
                print(f"[ç‰¹å¾µæª¢æ¸¬] SIFT ä¸å¯ç”¨ï¼Œä½¿ç”¨ ORB æª¢æ¸¬å™¨")
    
    elif detector_type == 'sift':
        try:
            detector = cv2.SIFT_create(
                nfeatures=max_keypoints,
                nOctaveLayers=4,
                contrastThreshold=0.03,
                edgeThreshold=8,
                sigma=1.4
            )
            actual_detector_type = 'sift'
        except:
            raise ValueError("SIFT æª¢æ¸¬å™¨ä¸å¯ç”¨ï¼Œè«‹æª¢æŸ¥ OpenCV ç‰ˆæœ¬ï¼ˆéœ€è¦ 4.5.1+ï¼‰æˆ–ä½¿ç”¨ 'orb' æˆ– 'akaze'")
    
    elif detector_type == 'orb':
        detector = cv2.ORB_create(
            nfeatures=max_keypoints,
            scaleFactor=1.2,
            nlevels=8,
            edgeThreshold=15,
            firstLevel=0,
            WTA_K=2,
            scoreType=cv2.ORB_HARRIS_SCORE,
            patchSize=31,
            fastThreshold=20
        )
        actual_detector_type = 'orb'
    
    elif detector_type == 'akaze':
        detector = cv2.AKAZE_create(
            descriptor_type=cv2.AKAZE_DESCRIPTOR_MLDB,
            descriptor_size=0,
            descriptor_channels=3,
            threshold=0.0005,    # é™ä½é–¾å€¼ä»¥ç²å¾—æ›´å¤šç‰¹å¾µé»
            nOctaves=4,
            nOctaveLayers=4,
            diffusivity=cv2.KAZE_DIFF_PM_G2
        )
        actual_detector_type = 'akaze'
    
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„æª¢æ¸¬å™¨é¡å‹: {detector_type}")
    
    # æª¢æ¸¬ç‰¹å¾µé»å’Œæè¿°å­
    keypoints, descriptors = detector.detectAndCompute(gray, None)
    
    if descriptors is None or len(keypoints) == 0:
        raise ValueError(f"æœªæª¢æ¸¬åˆ°ç‰¹å¾µé»ã€‚å»ºè­°ï¼š1) ä½¿ç”¨æ›´å¤§çš„åœ–åƒ 2) èª¿æ•´æª¢æ¸¬å™¨åƒæ•¸ 3) ç¢ºä¿åœ–åƒæ¸…æ™°")
    
    if verbose:
        print(f"[ç‰¹å¾µæª¢æ¸¬] æª¢æ¸¬åˆ° {len(keypoints)} å€‹ç‰¹å¾µé»")
    
    # ç¢ºä¿ keypoints å’Œ descriptors æ•¸é‡ä¸€è‡´
    if len(keypoints) != len(descriptors):
        raise ValueError(f"é—œéµé»å’Œæè¿°å­æ•¸é‡ä¸ä¸€è‡´: {len(keypoints)} vs {len(descriptors)}")
    
    # å°æ–¼ AKAZEï¼Œæ‰‹å‹•é™åˆ¶ç‰¹å¾µé»æ•¸é‡
    if actual_detector_type == 'akaze' and len(keypoints) > max_keypoints:
        kp_desc_pairs = list(zip(keypoints, descriptors))
        kp_desc_pairs.sort(key=lambda x: x[0].response, reverse=True)
        kp_desc_pairs = kp_desc_pairs[:max_keypoints]
        keypoints = [kp for kp, _ in kp_desc_pairs]
        descriptors = np.array([desc for _, desc in kp_desc_pairs])
        if descriptors.ndim == 1:
            descriptors = descriptors.reshape(1, -1)
        if verbose:
            print(f"[ç‰¹å¾µæª¢æ¸¬] AKAZE ç‰¹å¾µé»æ•¸é‡é™åˆ¶ç‚º {max_keypoints}")
    
    return actual_detector_type, keypoints, descriptors
```

#### æ”¹é€² RANSAC åƒæ•¸

åœ¨ `estimate_affine_partial` å‡½æ•¸ä¸­ä½¿ç”¨æ›´å¥½çš„åƒæ•¸ï¼š

```python
def estimate_affine_partial_enhanced(kp1, kp2, matches,
                                     ransac_reproj_thresh=2.0,  # å¾ 3.0 é™ä½åˆ° 2.0
                                     ransac_max_iters=5000,     # å¾ 2000 å¢åŠ åˆ° 5000
                                     ransac_confidence=0.995):  # å¾ 0.99 æé«˜åˆ° 0.995
    """
    å¢å¼·ç‰ˆä»¿å°„ä¼°è¨ˆï¼šä½¿ç”¨æ›´åš´æ ¼çš„ RANSAC åƒæ•¸
    
    Args:
        kp1: æ¨¡æ¿é—œéµé»åˆ—è¡¨
        kp2: å ´æ™¯é—œéµé»åˆ—è¡¨
        matches: åŒ¹é…åˆ—è¡¨
        ransac_reproj_thresh: RANSAC é‡æŠ•å½±é–¾å€¼ï¼ˆåƒç´ ï¼‰- æ›´åš´æ ¼
        ransac_max_iters: RANSAC æœ€å¤§è¿­ä»£æ¬¡æ•¸ - æ›´å¤šè¿­ä»£
        ransac_confidence: RANSAC ç½®ä¿¡åº¦ - æ›´é«˜ä¿¡å¿ƒ
    
    Returns:
        (affine_matrix, inliers_mask) æˆ– (None, None) å¦‚æœå¤±æ•—
    """
    if len(matches) < 3:
        raise ValueError(f"åŒ¹é…é»å¤ªå°‘ï¼ˆ{len(matches)}ï¼‰ï¼Œè‡³å°‘éœ€è¦ 3 å€‹é»")
    
    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)
    
    # å˜—è©¦ä½¿ç”¨ USAC_MAGSACï¼ˆå¦‚æœ OpenCV ç‰ˆæœ¬æ”¯æŒï¼‰
    try:
        method = cv2.USAC_MAGSAC  # OpenCV 4.5.4+
    except AttributeError:
        method = cv2.RANSAC  # å›é€€åˆ°æ¨™æº– RANSAC
    
    affine_matrix, inliers_mask = cv2.estimateAffinePartial2D(
        src_pts, dst_pts,
        method=method,
        ransacReprojThreshold=ransac_reproj_thresh,
        maxIters=ransac_max_iters,
        confidence=ransac_confidence,
        refineIters=20  # å¾ 10 å¢åŠ åˆ° 20
    )
    
    if affine_matrix is None:
        raise ValueError("ç„¡æ³•ä¼°è¨ˆä»¿å°„çŸ©é™£")
    
    inliers_mask = inliers_mask.ravel().astype(bool)
    
    return affine_matrix, inliers_mask
```

---

### 4. æ™ºèƒ½æ¨¡æ¿æ©ç¢¼ç”Ÿæˆ â­

**å¯¦æ–½é›£åº¦**ï¼šâ­ ä½åˆ°ä¸­  
**é æœŸæ•ˆæœ**ï¼šå°è¤‡é›œèƒŒæ™¯çš„æ¨¡æ¿ï¼Œæº–ç¢ºç‡ +15-20%

#### èƒŒæ™¯

æ‰‹å‹•å‰µå»º mask è²»æ™‚ä¸”å¯èƒ½ä¸æº–ç¢ºã€‚è‡ªå‹•ç”Ÿæˆé«˜è³ªé‡ mask å¯ä»¥ï¼š
- æ’é™¤èƒŒæ™¯å¹²æ“¾
- èšç„¦æ–¼é—œéµå€åŸŸ
- æé«˜ NCC å’Œ Chamfer çš„ç²¾åº¦

#### å¯¦ä½œ

å‰µå»ºæ–°æ–‡ä»¶ `sharp/mask_utils.py`ï¼š

```python
"""
æ¨¡æ¿æ©ç¢¼å·¥å…·ï¼šè‡ªå‹•ç”Ÿæˆé«˜è³ªé‡ ROI mask
"""

import cv2
import numpy as np


def create_edge_density_mask(img, threshold_percentile=50, 
                             morphology_kernel_size=5, blur_size=5):
    """
    åŸºæ–¼é‚Šç·£å¯†åº¦å‰µå»º mask
    
    åŸç†ï¼šä¿ç•™é‚Šç·£å¯†åº¦é«˜çš„å€åŸŸï¼Œèªç‚ºé€™äº›å€åŸŸæ˜¯å‰æ™¯ç‰©é«”ã€‚
    
    Args:
        img: è¼¸å…¥åœ–åƒï¼ˆç°åº¦æˆ– BGRï¼‰
        threshold_percentile: é‚Šç·£å¼·åº¦ç™¾åˆ†ä½é–¾å€¼ï¼ˆ0-100ï¼‰
        morphology_kernel_size: å½¢æ…‹å­¸æ“ä½œçš„æ ¸å¤§å°
        blur_size: é«˜æ–¯æ¨¡ç³Šæ ¸å¤§å°
    
    Returns:
        mask: äºŒå€¼æ©ç¢¼ï¼ˆuint8, 0 æˆ– 255ï¼‰
    """
    if img.ndim == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img
    
    # è¨ˆç®—é‚Šç·£
    edges = cv2.Canny(gray, 50, 150)
    
    # è†¨è„¹é‚Šç·£ä»¥é€£æ¥æ–·è£‚çš„é‚Šç·£
    kernel = np.ones((morphology_kernel_size, morphology_kernel_size), np.uint8)
    edges_dilated = cv2.dilate(edges, kernel, iterations=1)
    
    # è¨ˆç®—å±€éƒ¨é‚Šç·£å¯†åº¦ï¼ˆä½¿ç”¨æ¡†æ¿¾æ³¢ï¼‰
    edge_density = cv2.boxFilter(edges_dilated.astype(np.float32) / 255.0, -1, (21, 21))
    
    # åŸºæ–¼ç™¾åˆ†ä½æ•¸è‡ªå‹•é–¾å€¼
    threshold = np.percentile(edge_density, threshold_percentile)
    mask = (edge_density > threshold).astype(np.uint8) * 255
    
    # å½¢æ…‹å­¸é–‰é‹ç®—ï¼ˆå¡«å……å°æ´ï¼‰
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    
    # å½¢æ…‹å­¸é–‹é‹ç®—ï¼ˆç§»é™¤å°å™ªé»ï¼‰
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    
    return mask


def create_saliency_mask(img, saliency_type='SPECTRAL_RESIDUAL', 
                         threshold_method='otsu'):
    """
    åŸºæ–¼é¡¯è‘—æ€§æª¢æ¸¬å‰µå»º mask
    
    ä½¿ç”¨ OpenCV çš„é¡¯è‘—æ€§æª¢æ¸¬ç®—æ³•è‡ªå‹•è­˜åˆ¥å‰æ™¯ç‰©é«”ã€‚
    
    Args:
        img: è¼¸å…¥åœ–åƒï¼ˆBGRï¼‰
        saliency_type: é¡¯è‘—æ€§ç®—æ³•é¡å‹
            - 'SPECTRAL_RESIDUAL': å…‰è­œæ®˜å·®ï¼ˆå¿«é€Ÿï¼‰
            - 'FINE_GRAINED': ç²¾ç´°ç²’åº¦ï¼ˆè¼ƒæ…¢ä½†æ›´æº–ç¢ºï¼‰
        threshold_method: é–¾å€¼æ–¹æ³•
            - 'otsu': Otsu è‡ªå‹•é–¾å€¼
            - 'adaptive': è‡ªé©æ‡‰é–¾å€¼
            - float: æ‰‹å‹•é–¾å€¼ï¼ˆ0.0-1.0ï¼‰
    
    Returns:
        mask: äºŒå€¼æ©ç¢¼ï¼ˆuint8, 0 æˆ– 255ï¼‰
    """
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    
    # å‰µå»ºé¡¯è‘—æ€§æª¢æ¸¬å™¨
    if saliency_type == 'SPECTRAL_RESIDUAL':
        saliency = cv2.saliency.StaticSaliencySpectralResidual_create()
    elif saliency_type == 'FINE_GRAINED':
        saliency = cv2.saliency.StaticSaliencyFineGrained_create()
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„é¡¯è‘—æ€§é¡å‹: {saliency_type}")
    
    # è¨ˆç®—é¡¯è‘—æ€§åœ–
    success, saliency_map = saliency.computeSaliency(img)
    if not success:
        raise ValueError("é¡¯è‘—æ€§è¨ˆç®—å¤±æ•—")
    
    # æ­¸ä¸€åŒ–åˆ° [0, 255]
    saliency_map = (saliency_map * 255).astype(np.uint8)
    
    # æ‡‰ç”¨é–¾å€¼
    if threshold_method == 'otsu':
        _, mask = cv2.threshold(saliency_map, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    elif threshold_method == 'adaptive':
        mask = cv2.adaptiveThreshold(saliency_map, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                      cv2.THRESH_BINARY, 11, 2)
    elif isinstance(threshold_method, (int, float)):
        threshold = int(threshold_method * 255)
        _, mask = cv2.threshold(saliency_map, threshold, 255, cv2.THRESH_BINARY)
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„é–¾å€¼æ–¹æ³•: {threshold_method}")
    
    # å½¢æ…‹å­¸è™•ç†
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    
    return mask


def create_grabcut_mask(img, border_margin=10, iterations=5):
    """
    ä½¿ç”¨ GrabCut ç®—æ³•å‰µå»º mask
    
    GrabCut æ˜¯ä¸€ç¨®åŸºæ–¼åœ–å‰²çš„å‰æ™¯/èƒŒæ™¯åˆ†å‰²ç®—æ³•ã€‚
    å‡è¨­ç‰©é«”ä½æ–¼åœ–åƒä¸­å¿ƒå€åŸŸã€‚
    
    Args:
        img: è¼¸å…¥åœ–åƒï¼ˆBGRï¼‰
        border_margin: é‚Šç•Œç•™ç™½ï¼ˆåƒç´ ï¼‰ï¼Œç”¨æ–¼åˆå§‹åŒ–èƒŒæ™¯å€åŸŸ
        iterations: GrabCut è¿­ä»£æ¬¡æ•¸
    
    Returns:
        mask: äºŒå€¼æ©ç¢¼ï¼ˆuint8, 0 æˆ– 255ï¼‰
    """
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    
    h, w = img.shape[:2]
    
    # åˆå§‹åŒ– maskï¼ˆå…¨éƒ¨ç‚ºå¯èƒ½èƒŒæ™¯ï¼‰
    mask = np.zeros((h, w), np.uint8)
    
    # åˆå§‹åŒ–èƒŒæ™¯å’Œå‰æ™¯æ¨¡å‹
    bgd_model = np.zeros((1, 65), np.float64)
    fgd_model = np.zeros((1, 65), np.float64)
    
    # å®šç¾©çŸ©å½¢ ROIï¼ˆå‡è¨­ç‰©é«”åœ¨ä¸­å¿ƒï¼‰
    rect = (border_margin, border_margin, 
            w - 2 * border_margin, h - 2 * border_margin)
    
    # åŸ·è¡Œ GrabCut
    cv2.grabCut(img, mask, rect, bgd_model, fgd_model, 
                iterations, cv2.GC_INIT_WITH_RECT)
    
    # è½‰æ›ç‚ºäºŒå€¼ maskï¼ˆå‰æ™¯ + å¯èƒ½å‰æ™¯ï¼‰
    mask = np.where((mask == cv2.GC_FGD) | (mask == cv2.GC_PR_FGD), 255, 0).astype(np.uint8)
    
    return mask


def create_adaptive_mask(img, method='auto', **kwargs):
    """
    è‡ªå‹•é¸æ“‡æœ€ä½³æ–¹æ³•å‰µå»º mask
    
    Args:
        img: è¼¸å…¥åœ–åƒ
        method: mask ç”Ÿæˆæ–¹æ³•
            - 'auto': è‡ªå‹•é¸æ“‡ï¼ˆæ¨è–¦ï¼‰
            - 'edge_density': åŸºæ–¼é‚Šç·£å¯†åº¦
            - 'saliency': åŸºæ–¼é¡¯è‘—æ€§æª¢æ¸¬
            - 'grabcut': ä½¿ç”¨ GrabCut ç®—æ³•
        **kwargs: å‚³éçµ¦å…·é«”æ–¹æ³•çš„åƒæ•¸
    
    Returns:
        mask: äºŒå€¼æ©ç¢¼ï¼ˆuint8, 0 æˆ– 255ï¼‰
    """
    if method == 'auto':
        # è‡ªå‹•é¸æ“‡ç­–ç•¥
        # è¨ˆç®—åœ–åƒç‰¹æ€§
        if img.ndim == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        else:
            gray = img
        
        # è¨ˆç®—é‚Šç·£æ¯”ç‡
        edges = cv2.Canny(gray, 50, 150)
        edge_ratio = np.sum(edges > 0) / edges.size
        
        # è¨ˆç®—ç´‹ç†å¾©é›œåº¦ï¼ˆä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # æ ¹æ“šç‰¹æ€§é¸æ“‡æ–¹æ³•
        if edge_ratio > 0.15:
            # é‚Šç·£æ˜é¡¯ï¼šä½¿ç”¨é‚Šç·£å¯†åº¦
            method = 'edge_density'
        elif laplacian_var > 500:
            # ç´‹ç†è±å¯Œï¼šä½¿ç”¨é¡¯è‘—æ€§æª¢æ¸¬
            method = 'saliency'
        else:
            # é»˜èªï¼šä½¿ç”¨ GrabCut
            method = 'grabcut'
        
        print(f"[è‡ªå‹• Mask] é¸æ“‡æ–¹æ³•: {method} (edge_ratio={edge_ratio:.3f}, texture_var={laplacian_var:.1f})")
    
    # èª¿ç”¨ç›¸æ‡‰æ–¹æ³•
    if method == 'edge_density':
        return create_edge_density_mask(img, **kwargs)
    elif method == 'saliency':
        return create_saliency_mask(img, **kwargs)
    elif method == 'grabcut':
        return create_grabcut_mask(img, **kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„æ–¹æ³•: {method}")


def refine_mask_by_largest_component(mask, min_area_ratio=0.1):
    """
    ä¿ç•™ mask ä¸­æœ€å¤§çš„é€£é€šåˆ†é‡
    
    Args:
        mask: è¼¸å…¥ mask
        min_area_ratio: æœ€å°é¢ç©æ¯”ç‡ï¼ˆç›¸å°æ–¼åœ–åƒå¤§å°ï¼‰
    
    Returns:
        refined_mask: ç²¾ç´°åŒ–çš„ mask
    """
    # æŸ¥æ‰¾é€£é€šåˆ†é‡
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)
    
    if num_labels <= 1:  # åªæœ‰èƒŒæ™¯
        return mask
    
    # æ‰¾åˆ°æœ€å¤§çš„å‰æ™¯åˆ†é‡ï¼ˆå¿½ç•¥æ¨™ç±¤ 0ï¼Œå³èƒŒæ™¯ï¼‰
    largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
    largest_area = stats[largest_label, cv2.CC_STAT_AREA]
    
    # æª¢æŸ¥é¢ç©æ˜¯å¦è¶³å¤ å¤§
    total_area = mask.shape[0] * mask.shape[1]
    if largest_area < total_area * min_area_ratio:
        # é¢ç©å¤ªå°ï¼Œè¿”å›åŸå§‹ mask
        return mask
    
    # å‰µå»ºåªåŒ…å«æœ€å¤§åˆ†é‡çš„ mask
    refined_mask = np.where(labels == largest_label, 255, 0).astype(np.uint8)
    
    return refined_mask
```

#### ä½¿ç”¨ç¯„ä¾‹

```python
from sharp.mask_utils import create_adaptive_mask, refine_mask_by_largest_component

# è‡ªå‹•ç”Ÿæˆ mask
template = cv2.imread('template.png')
mask = create_adaptive_mask(template, method='auto')

# å¯é¸ï¼šç²¾ç´°åŒ– maskï¼ˆä¿ç•™æœ€å¤§é€£é€šåˆ†é‡ï¼‰
mask = refine_mask_by_largest_component(mask)

# ä¿å­˜ mask ä»¥ä¾›æª¢æŸ¥
cv2.imwrite('template_mask.png', mask)

# åœ¨åŒ¹é…ä¸­ä½¿ç”¨ mask
result = affine_match(template, scene)
refined_result = hybrid_refine_strategy(template, scene, result, mask=mask)
```

---

## éšæ®µäºŒï¼šé€²éšå„ª
```

